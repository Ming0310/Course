# easydict模块用于以属性的方式访问字典的值
from easydict import EasyDict as edict
# glob模块主要用于查找符合特定规则的文件路径名，类似使用windows下的文件搜索
import glob
# os模块主要用于处理文件和目录
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

import mindspore
# 导入mindspore框架数据集
import mindspore.dataset as ds
# vision.c_transforms模块是处理图像增强的高性能模块，用于数据增强图像数据改进训练模型。
import mindspore.dataset.vision.c_transforms as CV
# c_transforms模块提供常用操作，包括OneHotOp和TypeCast
import mindspore.dataset.transforms.c_transforms as C
from mindspore.common import dtype as mstype
from mindspore import context
# 导入模块用于初始化截断正态分布
from mindspore.common.initializer import TruncatedNormal
from mindspore import nn
from mindspore.train import Model
from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor
from mindspore.train.serialization import load_checkpoint, load_param_into_net
from mindspore import Tensor

# 设置MindSpore的执行模式和设备
context.set_context(mode=context.GRAPH_MODE, device_target="GPU")

import argparse

# 创建解析
parser = argparse.ArgumentParser(description="train flower classify",
                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)
# 添加参数
parser.add_argument('--data_url', type=str, help='the training data')

parser.add_argument('--train_url', type=str, help='the path model saved')

parser.add_argument('--test_url', type=str, help='the training data')

parser.add_argument('--epoch', type=int, help='the training data')

parser.add_argument('--lr', type=float, help='the training data')
# 解析参数
args, unkown = parser.parse_known_args()

cfg = edict({
    'data_path': args.data_url,
    'data_size': 3670,
    'image_width': 100,  # 图片宽度
    'image_height': 100,  # 图片高度
    'batch_size': 32,
    'channel': 3,  # 图片通道数
    'num_class': 6,  # 分类类别
    'weight_decay': 0.01,
    'lr': args.lr,  # 学习率
    'dropout_ratio': 0.5,
    'epoch_size': args.epoch,  # 训练次数
    'sigma': 0.01,

    'save_checkpoint_steps': 1,  # 多少步保存一次模型
    'keep_checkpoint_max': 1,  # 最多保存多少个模型
    'output_directory': args.train_url,  # 保存模型路径
    'output_prefix': "checkpoint_classification"  # 保存模型文件名字
})

# 解压数据集，只需要第一次运行时解压，第二次无需再解压
# !wget https://hciaai.obs.cn-north-4.myhuaweicloud.com:443/flower_photos.zip
# !unzip flower_photos.zip
# 从目录中读取图像的源数据集。
de_dataset = ds.ImageFolderDataset(cfg.data_path,
                                   class_indexing={'bee_balm': 0, 'blackberry_lily': 1, 'blanket_flower': 2,
                                                   'bougainvillea': 3,
                                                   'bromelia': 4, 'foxglove': 5})
# 解码前将输入图像裁剪成任意大小和宽高比。
transform_img = CV.RandomCropDecodeResize([cfg.image_width, cfg.image_height], scale=(0.08, 1.0),
                                          ratio=(0.75, 1.333))  # 改变尺寸
# 转换输入图像；形状（H, W, C）为形状（C, H, W）。
hwc2chw_op = CV.HWC2CHW()
# 转换为给定MindSpore数据类型的Tensor操作。
type_cast_op = C.TypeCast(mstype.float32)
# 将操作中的每个操作应用到此数据集。
de_dataset = de_dataset.map(input_columns="image", num_parallel_workers=8, operations=transform_img)
de_dataset = de_dataset.map(input_columns="image", operations=hwc2chw_op, num_parallel_workers=8)
de_dataset = de_dataset.map(input_columns="image", operations=type_cast_op, num_parallel_workers=8)
de_dataset = de_dataset.shuffle(buffer_size=cfg.data_size)
# 划分训练集测试集
(de_train, de_test) = de_dataset.split([0.8, 0.2])
# 设置每个批处理的行数
# drop_remainder确定是否删除最后一个可能不完整的批（default=False）。
# 如果为True，并且如果可用于生成最后一个批的batch_size行小于batch_size行，则这些行将被删除，并且不会传播到子节点。
de_train = de_train.batch(cfg.batch_size, drop_remainder=True)
# 重复此数据集计数次数。
de_test = de_test.batch(cfg.batch_size, drop_remainder=True)
print('训练数据集数量：', de_train.get_dataset_size() * cfg.batch_size)  # get_dataset_size()获取批处理的大小。
print('测试数据集数量：', de_test.get_dataset_size() * cfg.batch_size)

data_next = de_dataset.create_dict_iterator(output_numpy=True).__next__()
print('通道数/图像长/宽：', data_next['image'].shape)
print('一张图像的标签样式：', data_next['label'])  # 一共5类，用0-4的数字表达类别。

plt.figure()
plt.imshow(data_next['image'][0, ...])
plt.colorbar()
plt.grid(False)
plt.show()


# 定义CNN图像识别网络
class Identification_Net(nn.Cell):
    def __init__(self, num_class=6, channel=3, dropout_ratio=0.5, trun_sigma=0.01):  # 一共分五类，图片通道数是3
        super(Identification_Net, self).__init__()
        self.num_class = num_class
        self.channel = channel
        self.dropout_ratio = dropout_ratio
        self.conv1 = nn.Conv2d(self.channel, 32,
                               kernel_size=5, stride=1, padding=0,
                               has_bias=True, pad_mode="same",
                               weight_init=TruncatedNormal(sigma=trun_sigma), bias_init='zeros')
        # 设置ReLU激活函数
        self.relu = nn.ReLU()
        # 设置最大池化层
        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2, pad_mode="valid")
        self.conv2 = nn.Conv2d(32, 64,
                               kernel_size=5, stride=1, padding=0,
                               has_bias=True, pad_mode="same",
                               weight_init=TruncatedNormal(sigma=trun_sigma), bias_init='zeros')
        self.conv3 = nn.Conv2d(64, 128,
                               kernel_size=3, stride=1, padding=0,
                               has_bias=True, pad_mode="same",
                               weight_init=TruncatedNormal(sigma=trun_sigma), bias_init='zeros')
        self.conv4 = nn.Conv2d(128, 128,
                               kernel_size=3, stride=1, padding=0,
                               has_bias=True, pad_mode="same",
                               weight_init=TruncatedNormal(sigma=trun_sigma), bias_init='zeros')
        self.flatten = nn.Flatten()
        self.fc1 = nn.Dense(6 * 6 * 128, 1024, weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=0.1)
        self.dropout = nn.Dropout(self.dropout_ratio)
        self.fc2 = nn.Dense(1024, 512, weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=0.1)
        self.fc3 = nn.Dense(512, self.num_class, weight_init=TruncatedNormal(sigma=trun_sigma), bias_init=0.1)
        # self.sm = nn.Softmax()

    # 构建模型
    def construct(self, x):
        x = self.conv1(x)
        # print(x.shape)
        x = self.relu(x)
        x = self.max_pool2d(x)
        x = self.conv2(x)
        x = self.relu(x)
        x = self.max_pool2d(x)
        x = self.conv3(x)
        x = self.max_pool2d(x)
        x = self.conv4(x)
        x = self.max_pool2d(x)
        x = self.flatten(x)
        x = self.fc1(x)
        x = self.relu(x)
        # print(x.shape)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        return x


net = Identification_Net(num_class=cfg.num_class, channel=cfg.channel, dropout_ratio=cfg.dropout_ratio)
# 计算softmax交叉熵。
net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction="mean")
# opt
fc_weight_params = list(filter(lambda x: 'fc' in x.name and 'weight' in x.name, net.trainable_params()))
other_params = list(filter(lambda x: 'fc' not in x.name or 'weight' not in x.name, net.trainable_params()))
group_params = [{'params': fc_weight_params, 'weight_decay': cfg.weight_decay},
                {'params': other_params},
                {'order_params': net.trainable_params()}]
# 设置Adam优化器
net_opt = nn.Adam(group_params, learning_rate=cfg.lr, weight_decay=0.0)
# net_opt = nn.Adam(params=net.trainable_params(), learning_rate=cfg.lr, weight_decay=0.1)

model = Model(net, loss_fn=net_loss, optimizer=net_opt, metrics={"acc"})
loss_cb = LossMonitor(per_print_times=de_train.get_dataset_size() * 10)
config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,
                             keep_checkpoint_max=cfg.keep_checkpoint_max)
ckpoint_cb = ModelCheckpoint(prefix=cfg.output_prefix, directory=cfg.output_directory, config=config_ck)
print("============== Starting Training ==============")
model.train(cfg.epoch_size, de_train, callbacks=[loss_cb, ckpoint_cb], dataset_sink_mode=False)

# 使用测试集评估模型，打印总体准确率
metric = model.eval(de_test)
print(metric)

# # 预测
# path_test = args.test_url  # 测试图像的地址 （改为自己的）
# imgs = []  # 创建保存图像的空列表
# for im in glob.glob(path_test + '/*.jpg'):  # 利用glob.glob函数搜索每个层级文件下面符合特定格式“/*.jpg”进行遍历
#     print('reading the images:%s' % (im))  # 遍历图像的同时，打印每张图片的“路径+名称”信息
#     img = cv2.imread(im)  # 利用io.imread函数读取每一张被遍历的图像并将其赋值给img
#     img = cv2.resize(img, (100, 100))  # 利用cv2.resize函数对每张img图像进行大小缩放，统一处理为大小为w*h的图像
#     imgs.append(img)  # 将每张经过处理的图像数据保存在之前创建的imgs空列表当中
# imgs = np.asarray(imgs, np.float32)  # 利用np.asarray()函数对imgs进行数据转换
# imgs = imgs.transpose(0, 3, 1, 2)
# test = Tensor(imgs, mindspore.float32)
# predictions = model.predict(test)
# predictions = np.argmax(predictions.asnumpy(), axis=1)
# print(predictions)

# 预测
class_names = {0:'bee',1:'blackberry',2:'blanket',3:'bougainvillea',4:'bromelia',5:'foxglove'}
testpath = args.test_url
testdata = ds.ImageFolderDataset(dataset_dir=testpath,class_indexing={'bee':0,'blackberry':1,'blanket':2,'bougainvillea':3,'bromelia':4,'foxglove':5})

testdata = testdata.map(input_columns="image", num_parallel_workers=8, operations=transform_img)
testdata = testdata.map(input_columns="image", operations=hwc2chw_op, num_parallel_workers=8)
testdata = testdata.map(input_columns="image", operations=type_cast_op, num_parallel_workers=8)
testdata=testdata.batch(cfg.batch_size, drop_remainder=False)

it = testdata.create_dict_iterator(output_numpy=True, num_epochs=1)
test_ = it.__next__()
test = Tensor(test_["image"], mindspore.float32)
predictions = model.predict(test)
predictions = predictions.asnumpy()
true_label = test_["label"]

for i in range(6):
    p_np = predictions[i, :]
    pre_label = np.argmax(p_np)
    print('第' + str(i) + '个sample预测结果：', class_names[pre_label],"真实结果：",class_names[true_label[i]])
